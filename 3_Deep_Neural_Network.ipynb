{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhld_id</th>\n",
       "      <th>drvr_cnt</th>\n",
       "      <th>veh_cnt</th>\n",
       "      <th>min_age</th>\n",
       "      <th>hoh_age</th>\n",
       "      <th>max_age</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_mon_lic</th>\n",
       "      <th>hoh_mon_lic</th>\n",
       "      <th>max_mon_lic</th>\n",
       "      <th>...</th>\n",
       "      <th>naft_2012</th>\n",
       "      <th>naft_2013</th>\n",
       "      <th>naft_2014</th>\n",
       "      <th>naft_2015</th>\n",
       "      <th>naft_2016</th>\n",
       "      <th>aft_2012</th>\n",
       "      <th>aft_2013</th>\n",
       "      <th>aft_2014</th>\n",
       "      <th>aft_2015</th>\n",
       "      <th>aft_2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4317</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.370047</td>\n",
       "      <td>47.370047</td>\n",
       "      <td>47.370047</td>\n",
       "      <td>47.370047</td>\n",
       "      <td>333.539214</td>\n",
       "      <td>290.637858</td>\n",
       "      <td>290.637858</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3248</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>43.674743</td>\n",
       "      <td>48.459073</td>\n",
       "      <td>48.459073</td>\n",
       "      <td>46.066908</td>\n",
       "      <td>332.096922</td>\n",
       "      <td>389.508880</td>\n",
       "      <td>389.508880</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2797</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.956548</td>\n",
       "      <td>39.956548</td>\n",
       "      <td>39.956548</td>\n",
       "      <td>39.956548</td>\n",
       "      <td>287.478578</td>\n",
       "      <td>287.478578</td>\n",
       "      <td>287.478578</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.247208</td>\n",
       "      <td>16.247208</td>\n",
       "      <td>16.247208</td>\n",
       "      <td>16.247208</td>\n",
       "      <td>2.966494</td>\n",
       "      <td>2.966494</td>\n",
       "      <td>2.966494</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31.147024</td>\n",
       "      <td>31.147024</td>\n",
       "      <td>31.147024</td>\n",
       "      <td>31.147024</td>\n",
       "      <td>181.764288</td>\n",
       "      <td>181.764288</td>\n",
       "      <td>181.764288</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>1206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.802269</td>\n",
       "      <td>35.802269</td>\n",
       "      <td>35.802269</td>\n",
       "      <td>35.802269</td>\n",
       "      <td>237.627228</td>\n",
       "      <td>237.627228</td>\n",
       "      <td>237.627228</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>431</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.564529</td>\n",
       "      <td>39.564529</td>\n",
       "      <td>39.564529</td>\n",
       "      <td>39.564529</td>\n",
       "      <td>282.774349</td>\n",
       "      <td>282.774349</td>\n",
       "      <td>282.774349</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>3830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.062151</td>\n",
       "      <td>36.062151</td>\n",
       "      <td>36.062151</td>\n",
       "      <td>36.062151</td>\n",
       "      <td>240.745810</td>\n",
       "      <td>240.745810</td>\n",
       "      <td>240.745810</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>919</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.726766</td>\n",
       "      <td>32.726766</td>\n",
       "      <td>32.726766</td>\n",
       "      <td>32.726766</td>\n",
       "      <td>200.721196</td>\n",
       "      <td>200.721196</td>\n",
       "      <td>200.721196</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>2454</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49.519857</td>\n",
       "      <td>66.320376</td>\n",
       "      <td>66.320376</td>\n",
       "      <td>57.920117</td>\n",
       "      <td>402.238287</td>\n",
       "      <td>603.844509</td>\n",
       "      <td>603.844509</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2281 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hhld_id  drvr_cnt  veh_cnt    min_age    hoh_age    max_age    avg_age  \\\n",
       "0        4317         1        1  47.370047  47.370047  47.370047  47.370047   \n",
       "2        3248         2        2  43.674743  48.459073  48.459073  46.066908   \n",
       "3        2797         1        2  39.956548  39.956548  39.956548  39.956548   \n",
       "4        1301         1        1  16.247208  16.247208  16.247208  16.247208   \n",
       "5         264         1        1  31.147024  31.147024  31.147024  31.147024   \n",
       "...       ...       ...      ...        ...        ...        ...        ...   \n",
       "2450     1206         1        1  35.802269  35.802269  35.802269  35.802269   \n",
       "2452      431         1        2  39.564529  39.564529  39.564529  39.564529   \n",
       "2453     3830         1        1  36.062151  36.062151  36.062151  36.062151   \n",
       "2454      919         1        1  32.726766  32.726766  32.726766  32.726766   \n",
       "2455     2454         2        2  49.519857  66.320376  66.320376  57.920117   \n",
       "\n",
       "      min_mon_lic  hoh_mon_lic  max_mon_lic  ...  naft_2012  naft_2013  \\\n",
       "0      333.539214   290.637858   290.637858  ...          0          0   \n",
       "2      332.096922   389.508880   389.508880  ...          0          0   \n",
       "3      287.478578   287.478578   287.478578  ...          0          1   \n",
       "4        2.966494     2.966494     2.966494  ...          0          0   \n",
       "5      181.764288   181.764288   181.764288  ...          0          0   \n",
       "...           ...          ...          ...  ...        ...        ...   \n",
       "2450   237.627228   237.627228   237.627228  ...          0          0   \n",
       "2452   282.774349   282.774349   282.774349  ...          0          0   \n",
       "2453   240.745810   240.745810   240.745810  ...          0          0   \n",
       "2454   200.721196   200.721196   200.721196  ...          1          0   \n",
       "2455   402.238287   603.844509   603.844509  ...          1          0   \n",
       "\n",
       "      naft_2014  naft_2015  naft_2016  aft_2012 aft_2013  aft_2014  aft_2015  \\\n",
       "0             0          0          0         0        0         0         0   \n",
       "2             2          0          0         0        0         1         0   \n",
       "3             0          0          0         0        0         0         0   \n",
       "4             1          0          0         0        1         0         0   \n",
       "5             0          1          0         1        0         0         0   \n",
       "...         ...        ...        ...       ...      ...       ...       ...   \n",
       "2450          0          1          1         0        0         0         0   \n",
       "2452          0          0          0         0        0         1         0   \n",
       "2453          1          0          0         0        0         0         0   \n",
       "2454          0          0          0         0        0         0         0   \n",
       "2455          0          0          0         0        0         0         0   \n",
       "\n",
       "      aft_2016  \n",
       "0            1  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "5            0  \n",
       "...        ...  \n",
       "2450         0  \n",
       "2452         0  \n",
       "2453         0  \n",
       "2454         0  \n",
       "2455         0  \n",
       "\n",
       "[2281 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('1_Merged_Data.csv')\n",
    "booleandf = df.select_dtypes(include=[bool])\n",
    "booleanDictionary = {True: 'TRUE', False: 'FALSE'}\n",
    "for column in booleandf:\n",
    "    df[column] = df[column].map(booleanDictionary)\n",
    "df = df.drop(columns=[\"veh_lien_cnt\"])\n",
    "df = df.dropna()\n",
    "df.dtypes\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1459 train examples\n",
      "365 validation examples\n",
      "457 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=4)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('future_clm_ind')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='min_age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='max_age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='avg_age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='hoh_age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='min_mon_lic', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='max_mon_lic', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='avg_mon_lic', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='hoh_mon_lic', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='avg_majr_viol', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='prior_bi', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='time_w_carr', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='avg_minr_viol', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='credit_score', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='drvr_cnt', vocabulary_list=(1, 2, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='veh_cnt', vocabulary_list=(1, 2, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_yth', vocabulary_list=(0, 1, 3, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_female', vocabulary_list=(0, 1, 2, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_male', vocabulary_list=(1, 2, 0, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_married', vocabulary_list=(0, 1, 2, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_single', vocabulary_list=(1, 2, 0, 4, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_auto', vocabulary_list=(1, 2, 0, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_mtrcyc', vocabulary_list=(0, 1, 3, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_majr_viol', vocabulary_list=(0, 1, 2, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_minr_viol', vocabulary_list=(0, 1, 2, 3, 4, 5), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='cnt_lic_susp', vocabulary_list=(0, 1), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='veh_lease_cnt', vocabulary_list=(0, 1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='veh_own_cnt', vocabulary_list=(0, 1, 2, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='monthly_pay_ind', vocabulary_list=(0, 1), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='veh_w_coll_cnt', vocabulary_list=(1, 0, 2, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='veh_w_comp_cnt', vocabulary_list=(1, 2, 0, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='veh_w_ers_cnt', vocabulary_list=(1, 0, 2, 4, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='curnt_bi_low', vocabulary_list=(50, 250, 25, 100), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='curnt_bi_upp', vocabulary_list=(50, 250, 25, 100), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='naft_2012', vocabulary_list=(0, 1, 2, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='naft_2013', vocabulary_list=(0, 1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='naft_2014', vocabulary_list=(0, 2, 1, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='naft_2015', vocabulary_list=(0, 1, 2, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='naft_2016', vocabulary_list=(0, 1, 2, 3), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='aft_2012', vocabulary_list=(0, 1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='aft_2013', vocabulary_list=(0, 1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='aft_2014', vocabulary_list=(0, 1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='aft_2015', vocabulary_list=(0, 1), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='aft_2016', vocabulary_list=(1, 0, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='hoh_married', vocabulary_list=('FALSE', 'TRUE'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='inforce_ind', vocabulary_list=(1,), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='fire_ind', vocabulary_list=(0, 1), dtype=tf.int64, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='homeowner_ind', vocabulary_list=(0, 1), dtype=tf.int64, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = []\n",
    "\n",
    "num_features = ['min_age', 'max_age', 'avg_age', 'hoh_age', 'min_mon_lic','max_mon_lic',\n",
    "      'avg_mon_lic', 'hoh_mon_lic', 'avg_majr_viol', 'prior_bi','time_w_carr','avg_minr_viol', 'credit_score']\n",
    "cat_features = ['drvr_cnt', 'veh_cnt', \n",
    "       'cnt_yth', 'cnt_female', 'cnt_male', 'cnt_married', 'cnt_single',\n",
    "       'cnt_auto', 'cnt_mtrcyc',\n",
    "       'cnt_majr_viol', 'cnt_minr_viol', 'cnt_lic_susp', \n",
    "       'veh_lease_cnt', 'veh_own_cnt', 'monthly_pay_ind',\n",
    "       'veh_w_coll_cnt', 'veh_w_comp_cnt', 'veh_w_ers_cnt', 'curnt_bi_low',\n",
    "       'curnt_bi_upp', 'naft_2012', 'naft_2013', 'naft_2014',\n",
    "       'naft_2015', 'naft_2016', 'aft_2012', 'aft_2013', 'aft_2014',\n",
    "       'aft_2015', 'aft_2016']\n",
    "ind_features = ['hoh_married', 'inforce_ind','fire_ind', 'homeowner_ind']\n",
    "\n",
    "# numeric features\n",
    "for header in num_features:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "    \n",
    "# categorical features\n",
    "for col_name in cat_features:\n",
    "    categorical_column = feature_column.categorical_column_with_vocabulary_list\\\n",
    "    (col_name, df[col_name].unique())\n",
    "    indicator_column = feature_column.indicator_column(categorical_column)\n",
    "    feature_columns.append(indicator_column)\n",
    "    \n",
    "# indicator features\n",
    "\n",
    "for col_name in ind_features:\n",
    "    categorical_column = feature_column.categorical_column_with_vocabulary_list\\\n",
    "    (col_name, df[col_name].unique())\n",
    "    indicator_column = feature_column.indicator_column(categorical_column)\n",
    "    feature_columns.append(indicator_column)\n",
    "\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 65.2120 - accuracy: 0.9164 - val_loss: 55.2956 - val_accuracy: 0.9260\n",
      "Epoch 2/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 30.3020 - accuracy: 0.9184 - val_loss: 65.9656 - val_accuracy: 0.9260\n",
      "Epoch 3/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 21.4365 - accuracy: 0.9102 - val_loss: 14.3625 - val_accuracy: 0.9178\n",
      "Epoch 4/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 14.6728 - accuracy: 0.9054 - val_loss: 24.6902 - val_accuracy: 0.9260\n",
      "Epoch 5/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 8.2130 - accuracy: 0.9150 - val_loss: 4.6395 - val_accuracy: 0.8658\n",
      "Epoch 6/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 3.1256 - accuracy: 0.8869 - val_loss: 3.8066 - val_accuracy: 0.9260\n",
      "Epoch 7/10\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 2.4910 - accuracy: 0.9020 - val_loss: 2.3213 - val_accuracy: 0.9260\n",
      "Epoch 8/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 1.7152 - accuracy: 0.9013 - val_loss: 3.5656 - val_accuracy: 0.9260\n",
      "Epoch 9/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.9985 - accuracy: 0.8951 - val_loss: 1.3872 - val_accuracy: 0.9260\n",
      "Epoch 10/10\n",
      "46/46 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.9020 - val_loss: 0.4540 - val_accuracy: 0.9260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a35bb59d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(140, activation='relu'),\n",
    "  layers.Dense(100, activation='relu'),\n",
    "  layers.Dense(60, activation='relu'),\n",
    "  layers.Dropout(0.1),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(), \\\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9409190371991247\n",
      "0.8612350526503659\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_test = test.future_clm_ind\n",
    "y_pred = model.predict(test_ds)\n",
    "print(metrics.accuracy_score(y_test, y_pred.round(), normalize=False)/457)\n",
    "print(metrics.roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
